{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dad16552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "#To scale the data using z-score \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Algorithms to use\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#To tune the model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Metrics to evaluate the model\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve, accuracy_score\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "728d66cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading datasets\n",
    "\n",
    "df = pd.read_csv(\"game_train.csv\")\n",
    "test = pd.read_csv(\"game_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55852d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10494 entries, 0 to 10493\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   review_id        10494 non-null  int64  \n",
      " 1   title            10494 non-null  object \n",
      " 2   year             10386 non-null  float64\n",
      " 3   user_review      10494 non-null  object \n",
      " 4   user_suggestion  10494 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 410.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "865671da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to print classification report and get confusion matrix in a proper format\n",
    "\n",
    "def metrics_score(actual, predicted):\n",
    "    print(classification_report(actual, predicted))\n",
    "    cm = confusion_matrix(actual, predicted)\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.heatmap(cm, annot=True,  fmt='.2f', xticklabels=['Not Canceled', 'Canceled'], yticklabels=['Not Canceled', 'Canceled'])\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c5ce0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "814c8b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>user_review</th>\n",
       "      <th>user_suggestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>473</td>\n",
       "      <td>Sakura Clicker</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>This has helped me through my stage 8 terminal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22971</td>\n",
       "      <td>Crusaders of the Lost Idols</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Awesome idea. I support this game. I love that...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18225</td>\n",
       "      <td>RaceRoom Racing Experience</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>This game is just, such a♥♥♥♥♥♥take. The devel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17132</td>\n",
       "      <td>Black Squad</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Early Access Reviewhere what i honesty think a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8103</td>\n",
       "      <td>DCS World Steam Edition</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Very detailed sim and a joy to fly using a fli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                        title    year  \\\n",
       "0        473               Sakura Clicker  2017.0   \n",
       "1      22971  Crusaders of the Lost Idols  2017.0   \n",
       "2      18225   RaceRoom Racing Experience  2014.0   \n",
       "3      17132                  Black Squad  2018.0   \n",
       "4       8103      DCS World Steam Edition  2014.0   \n",
       "\n",
       "                                         user_review  user_suggestion  \n",
       "0  This has helped me through my stage 8 terminal...                1  \n",
       "1  Awesome idea. I support this game. I love that...                1  \n",
       "2  This game is just, such a♥♥♥♥♥♥take. The devel...                0  \n",
       "3  Early Access Reviewhere what i honesty think a...                1  \n",
       "4  Very detailed sim and a joy to fly using a fli...                1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fba39c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Awesome idea. I support this game. I love that it keeps making progress even when you arent playing, so you have this huge stash of gold when you come back sometimes. My only complaint is that the in-game achievements don't transfer to Steam achievements.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1]['user_review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bab5dd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \\r and \\n\n",
    "df['user_review_Parsed_1'] = df['user_review'].str.replace(\"\\r\", \" \")\n",
    "df['user_review_Parsed_1'] = df['user_review_Parsed_1'].str.replace(\"\\n\", \" \")\n",
    "df['user_review_Parsed_1'] = df['user_review_Parsed_1'].str.replace(\"    \", \" \")\n",
    "df['user_review_Parsed_1'] = df['user_review_Parsed_1'].str.replace('\"', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6d3b0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user_review_Parsed_2'] = df['user_review_Parsed_1'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9ac108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_signs = list(\"?:!.,;\")\n",
    "df['user_review_Parsed_3'] = df['user_review_Parsed_2']\n",
    "\n",
    "for punct_sign in punctuation_signs:\n",
    "    df['user_review_Parsed_3'] = df['user_review_Parsed_3'].str.replace(punct_sign, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d3240f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user_review_Parsed_4'] = df['user_review_Parsed_3'].str.replace(\"'s\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbaf6b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\cyilee\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\cyilee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "print(\"------------------------------------------------------------\")\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "445b55e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the lemmatizer into an object\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3648115e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = len(df)\n",
    "lemmatized_text_list = []\n",
    "\n",
    "for row in range(0, nrows):\n",
    "    \n",
    "    # Create an empty list containing lemmatized words\n",
    "    lemmatized_list = []\n",
    "    \n",
    "    # Save the text and its words into an object\n",
    "    text = df.loc[row]['user_review_Parsed_4']\n",
    "    text_words = text.split(\" \")\n",
    "\n",
    "    # Iterate through every word to lemmatize\n",
    "    for word in text_words:\n",
    "        lemmatized_list.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n",
    "        \n",
    "    # Join the list\n",
    "    lemmatized_text = \" \".join(lemmatized_list)\n",
    "    \n",
    "    # Append to the list containing the texts\n",
    "    lemmatized_text_list.append(lemmatized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da1df5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user_review_Parsed_5'] = lemmatized_text_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62022618",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cyilee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading the stop words list\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af3f72f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the stop words in english\n",
    "stop_words = list(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2080ed1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user_review_Parsed_6'] = df['user_review_Parsed_5']\n",
    "\n",
    "for stop_word in stop_words:\n",
    "\n",
    "    regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n",
    "    df['user_review_Parsed_6'] = df['user_review_Parsed_6'].str.replace(regex_stopword, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47f9871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aa3c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf363285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99df2ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c8eb84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c406aa24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6decafc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741a0239",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_0 = RandomForestClassifier(random_state = 8)\n",
    "\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf_0.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bb7689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_estimators\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 1000, num = 5)]\n",
    "\n",
    "# max_features\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# max_depth\n",
    "max_depth = [int(x) for x in np.linspace(20, 100, num = 5)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# min_samples_split\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# min_samples_leaf\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# bootstrap\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def5ecb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create the base model to tune\n",
    "rfc = RandomForestClassifier(random_state=8)\n",
    "\n",
    "# Definition of the random search\n",
    "random_search = RandomizedSearchCV(estimator=rfc,\n",
    "                                   param_distributions=random_grid,\n",
    "                                   n_iter=50,\n",
    "                                   scoring='accuracy',\n",
    "                                   cv=3, \n",
    "                                   verbose=1, \n",
    "                                   random_state=8)\n",
    "\n",
    "# Fit the random search model\n",
    "random_search.fit(X_train[\"user_review\"], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a843cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
